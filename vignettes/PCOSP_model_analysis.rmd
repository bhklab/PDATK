---
title: "PCOSP: Pancreatic Cancer Overall Survival Predictor"
author:
- name: Vandana Sandhu
- name: Heewon Seo
- name: Christopher Eeles
  affiliation:
  - &pm Bioinformatics and Computational Genomics Laboratory, Princess Margaret Cancer Center,University Health Network, Toronto, Ontario, Canada
  email: christopher.eeles@uhnresearch.ca
- name: Benjamin Haibe-Kains
  affiliation:
  - *pm
  - &mbp Department of Medical Biophysics, University of Toronto, Toronto, Canada
  email: benjamin.haibe.kains@utoronto.ca
date: 2021-02-01
output:
    BiocStyle::html_document
vignette: >
    %\VignetteIndexEntry{PCOSP: Pancreatic Cancer Overall Survival Predictor}
    %\VignetteEngine{knitr::rmarkdown}
    %\VignetteEncoding{UTF-8}
---

# Pancreate Cancer Overall Survival Predictor

As an example of the utility of the PDATK package, we will provide code
replicating the analysis published in <insert PCSOP citation>. While the
code presented here is run on dummy data to ensure that PDATK is not too large,
the full data from that study can be downloaded from <where to download it?>.

```{r load_dependencies, message=FALSE, warning=FALSE, include=FALSE}
library(PDATK)
library(msigdbr)
```
```{r load_sample_data}
data(sampleCohortList)
sampleCohortList
```

## Split Training and Validation Data

To get started using PDATK, we recommend you place your patient cohorts into
`SurvivalExperiment` objects and then assemble those into a master `CohortList`,
which holds the training and validatino data for use with the various
`SurvivalModel`s in this package.


```{r subset_and_split_data}
commonGenes <- findCommonGenes(sampleCohortList)
# Subsets all list items, with subset for specifying rows and select for
# specifying columns
cohortList <- subset(sampleCohortList, subset=commonGenes)

ICGCcohortList <- cohortList[grepl('ICGC', names(cohortList), ignore.case=TRUE)]
validationCohortList <- cohortList[!grepl('icgc', names(cohortList),
    ignore.case=TRUE)]
```

Since we are interested in predicting survival, it is necessary to remove
patients with insufficient data to be useful. In general, we want to remove
patients who did not have an event in our period of interest. As such we remove
samples who dropped out of a study, but did not pass away before the first year.

```{r drop_not_censored_patients}
validationCohortList <- dropNotCensored(validationCohortList)
ICGCcohortList <- dropNotCensored(ICGCcohortList)
```
We have now split our data into training and validation data. For this analysis
we will be training using the ICGC cohorts, which includes one cohort with
RNA microarray data and another with RNA sequencing data. When using multiple
cohorts to train a model, it is required that those cohorts share samples. As
a result we will take as training data all patients shared between the two
cohorts and leave the remainder of patients as part of our validationData.

```{r split_train_test}
# find common samples between our training cohort in a cohort list
commonSamples <- findCommonSamples(ICGCcohortList)

# split into shared samples for training, the rest for testing
ICGCtrainCohorts <- subset(ICGCcohortList, select=commonSamples)
ICGCtestCohorts <- subset(ICGCcohortList, select=commonSamples, invert=TRUE)

# merge our training cohort test data into the rest of the validation data
validationCohortList <- c(ICGCtestCohorts, validationCohortList)
```

## Setup A `PCOSP` Model Object

We now have molecular data, annotated with the number of days survived since
treatment and the survival status and are ready to apply a `SurvivalModel` to
this data. In this example, we are applying a Pancreatic Cancer Overall Survival
Model, as described in <PCOSP_paper reference>. This object uses the `switchBox`
package to create an ensembl of binary classifiers, whos votes are then tallied
into a PCOSP score. A PCOSP score is simply the proportion of models predicting
good survival out of the total number of models in the ensembl.

```{r build_PCOSP_model}
PCOSPmodel <- PCOSP(ICGCtrainCohorts, minDaysSurvived=365, randomSeed=1987)

# view the model parameters; these make your model run reproducible
metadata(PCOSPmodel)$modelParams
```
## Training a PCOSP Model

To simplify working with different `SurvivalModel`, we have implemented a
standard workflow that is valid for all `SurvivalModel`s. This involves first
training the model, then using it to predict risk/risk-classes for a set
of validation cohorts and finally assessing performance on the validation data.

To train a model, the `trainModel` method is used. This function abstracts away
the implementation of model training, allowing end-users to focus on applying
the `SurvivalModel` to make predictions without a need to understand the model
internals. We hope this will make the package useful for those unfamiliar or
uninterested in the details of survival prediction methods.

For training a PCOSP model there are two parameters. First, `numModels` is the
number of models to train for use in the ensembl classifier to predict PCOSP
scores. To keep computation brief, we are only training 10 models. However, it
is recommended to use a minimum of 1000 for real world applications. The second
paramter is `minAccuracy`, which is the minimum model accuracy for a trained
model to included in the final model ensemble. Paradoxically, increasing this
too high can actually decrease the overall performance of the PCOSP model; we
recommend 0.6 as a sweet spot between random chance and overfitting.

```{r}
trainedPCOSPmodel <- trainModel(PCOSPmodel, numModels=10, minAccuracy=0.6)

metadata(trainedPCOSPmodel)$modelParams
```
We can see that after training, the additional model parameters are added to the
`modelParams` item in the model `metadata`. The goal is to ensure that your
model training, prediction and validation are fully reproducible by capturing
the parameters relevant to a specific model.

## Risk Prediction with a PCOSP Model

After training, a model can now be used with new data to make risk predicitons
and classify samples into 'good' or 'bad' survival groups. To do this, the
standard `predictClasses` method is used. Similar to `trainData`, we have
abstracted away the implementation details to provide users with a simple,
consistent interface to the use of `SurvivalModel` objects for making
predictions.

```{r }
PCOSPpredValCohorts <- predictClasses(validationCohortList,
    model=trainedPCOSPmodel)
```

The returned `CohortList` object now indicates that each of the cohorts have
predictions. This information is available in the `elementMetadata` slot of
the cohort list and can be accessed with the `mcols` function from `S4Vectors`.

```{r predicted_elementMetadata}
mcols(PCOSPpredValCohorts)
```
Predicting classes with a specific model adds a corresponding metadata
column to the object `colData`. In the case of a `PCOSP` model, the new column
is called `PCOSP_prob_good` and represents the proportion of models in the
ensemble which predicted good survival for a given sample.

```{r }
knitr::kable(head(colData(PCOSPpredValCohorts[[1]])))
```

Additionally, binary predictions of good or bad survival can be found in the
`PCOSPpredictions` item of each `SurvivalExperiment`s `metadata`. This contains
the raw predictions from the model for each classifier in the ensembl, ordered
by classifier accuracy. This data is not important for end users, but is used
internally when calculating validation statistics for the model.

```{r}
knitr::kable(metadata(PCOSPpredValCohorts[[1]])$PCOSPpredictions[1:5, 1:5])
```



